{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Look at the intensities"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from src.data  import read_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% import custom package\n",
     "is_executing": false
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5d0f835239b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m  \u001b[1;32mimport\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Code\\repos\\psd95_segmentation\\src\\data\\read_data.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;31m# %% Run stuff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m \u001b[0mplot_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprc_green\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m350\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;31m# %% Get Karl's csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_histogram' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'plot_histogram' is not defined",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-654248dcb4af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mread_channel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_channel' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'read_channel' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "# %% Run stuff\n",
    "channel = \"green\"\n",
    "padding = [[0, 0], [50, 500], [20, 20]]\n",
    "\n",
    "pallium_path = Path(\"D:/Code/repos/psd95_segmentation/data/raw/pallium\")\n",
    "files = [x for x in pallium_path.glob('*tif') if x.is_file()]\n",
    "\n",
    "num_prc = 11\n",
    "prc_green = np.zeros((len(files), num_prc))\n",
    "\n",
    "for count, file_name in enumerate(files):\n",
    "    print(count)\n",
    "    my_img = read_channel(channel, file_name.as_posix(), padding)\n",
    "    prc_green[count, :] = get_percentiles(my_img)\n",
    "\n",
    "\n",
    "# %% Run stuff\n",
    "with open('prc_green.pickle', 'wb') as f:\n",
    "    pickle.dump(prc_green, f)\n",
    "\n",
    "# %% Run stuff\n",
    "plot_histogram(prc_green[:, 6], 350, 50)\n",
    "\n",
    "# %% Get Karl's csv\n",
    "info_df = pd.read_csv('D:/Code/repos/psd95_segmentation/data/raw/karls_good2.csv')\n",
    "\n",
    "# %% Get a slice with year info\n",
    "info_year = info_df.loc[:, ['Source Image', 'Subject Issue Date']].sort_values(by=['Source Image'])\n",
    "info_year.drop_duplicates(subset='Source Image', inplace=True)\n",
    "\n",
    "# %%\n",
    "path_text = files[0].as_posix().split(sep='/')[-1].split(sep='.')[0].split(sep='_')[-1]\n",
    "\n",
    "# %% match files with year\n",
    "years = np.zeros((len(files), 1))\n",
    "names = []\n",
    "for count, file_name in enumerate(files):\n",
    "    img_name = get_image_name(file_name)\n",
    "    year = info_year.loc[info_year['Source Image'] == img_name,\n",
    "                         'Subject Issue Date'].values[0].split(sep='-')[0]\n",
    "    print(f\"#{count} image {img_name} year {year}\")\n",
    "    years[count] = year\n",
    "    names.append(img_name)\n",
    "\n",
    "# %% merge year w percentile\n",
    "img_intensity_df = pd.DataFrame(np.concatenate((years, prc_green), axis=1),\n",
    "                                columns=['Year', 'green_prc_0', 'green_prc_10',\n",
    "                                         'green_prc_20', 'green_prc_30',\n",
    "                                         'green_prc_40', 'green_prc_50',\n",
    "                                         'green_prc_60', 'green_prc_70',\n",
    "                                         'green_prc_80', 'green_prc_90',\n",
    "                                         'green_prc_100'])\n",
    "\n",
    "# %% merge year w percentile\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(img_intensity_df, alpha=0.2, figsize=(6, 6), diagonal='kde')\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# %%\n",
    "fig = plot_boxplot(img_intensity_df, 'Year', 'green_prc_100')\n",
    "print (type(fig))\n",
    "# %%\n",
    "fig.savefig('green_prc_100.png')\n",
    "\n",
    "# %%\n",
    "y_axis = 'nuc_prc_90'\n",
    "fig = plot_boxplot(img_intensity_df, 'Year', y_axis)\n",
    "fig.savefig(y_axis + '.png')\n",
    "\n",
    "# %% Run stuff\n",
    "channel = \"red\"\n",
    "prc_red = np.zeros((len(files), num_prc))\n",
    "for count, file_name in enumerate(files):\n",
    "    print(count)\n",
    "    my_img = read_channel(channel, file_name.as_posix(), padding)\n",
    "    prc_red[count, :] = get_percentiles(my_img)\n",
    "\n",
    "# %%\n",
    "img_intensity_df = pd.DataFrame(np.concatenate((years, prc_green, prc_red), axis=1),\n",
    "                                columns=['Year', 'green_prc_0', 'green_prc_10',\n",
    "                                         'green_prc_20', 'green_prc_30',\n",
    "                                         'green_prc_40', 'green_prc_50',\n",
    "                                         'green_prc_60', 'green_prc_70',\n",
    "                                         'green_prc_80', 'green_prc_90',\n",
    "                                         'green_prc_100',\n",
    "                                         'red_prc_0', 'red_prc_10',\n",
    "                                         'red_prc_20', 'red_prc_30',\n",
    "                                         'red_prc_40', 'red_prc_50',\n",
    "                                         'red_prc_60', 'red_prc_70',\n",
    "                                         'red_prc_80', 'red_prc_90',\n",
    "                                         'red_prc_100'])\n",
    "img_intensity_df.insert(0, 'Name', names, True)\n",
    "# %%\n",
    "feature = 'red_prc_0'\n",
    "fig = plot_boxplot(img_intensity_df, 'Year', feature)\n",
    "fig.savefig(feature + '.png')\n",
    "\n",
    "# %%\n",
    "info_df.sort_values(by=\"ID\", inplace=True)\n",
    "# %% match files with year\n",
    "years = np.zeros((len(files), 1))\n",
    "\n",
    "# %% match files with year\n",
    "\n",
    "id_segments = []\n",
    "timepoint = []\n",
    "for count, file_name in enumerate(files):\n",
    "    img_name = get_image_name(file_name)\n",
    "    id_segment = info_df.loc[info_df['Source Image'] == img_name, 'ID'].values[0]\n",
    "    print(f\"#{count} image {img_name} ID {id_segment}\")\n",
    "    id_segments.append(id_segment)\n",
    "\n",
    "    if id_segment[-2] == '6' or id_segment[-2] == '5':\n",
    "        timepoint.append(2)\n",
    "    elif id_segment[-2] == '3' or id_segment[-2] == '2':\n",
    "        timepoint.append(1)\n",
    "    else:\n",
    "        raise ValueError('weird time point')\n",
    "\n",
    "# %%\n",
    "img_intensity_df.insert(1, 'tp', timepoint, True)\n",
    "\n",
    "# %% download w redirect\n",
    "\n",
    "link_head = 'https://synapse.isrd.isi.edu'\n",
    "nuc_path = 'D:/Code/repos/psd95_segmentation/data/raw/csv/pallium/nuc/'\n",
    "nuc_url = []\n",
    "for count, file_name in enumerate(files):\n",
    "    img_name = get_image_name(file_name)\n",
    "    url = info_df.loc[info_df['Source Image'] == img_name, 'Segments Filtered URL'].iloc[0]\n",
    "    if url.split('.')[1] == 'nuclei_only':\n",
    "        url = link_head + url\n",
    "        print(f\"#{count} image {img_name} url {url}\")\n",
    "\n",
    "        nuc_url.append(url)\n",
    "\n",
    "        nuc_csv = requests.get(url, allow_redirects=True)\n",
    "        open(nuc_path + img_name + '_nuclei_only.csv', 'wb').write(nuc_csv.content)\n",
    "\n",
    "# %% look at intensity of the nuclei\n",
    "img_intensity_df = pd.read_csv('img_intensity_df.csv')\n",
    "img_names = img_intensity_df.iloc[:, 1]\n",
    "\n",
    "nuc_prc = np.zeros((len(img_names), 5))\n",
    "for count, img_name in enumerate(img_names):\n",
    "    print(f\"#{count} image {img_name}\")\n",
    "\n",
    "    csv_file = nuc_path + img_name + '_nuclei_only.csv'\n",
    "    nuc_csv_df = pd.read_csv(csv_file, skiprows=[1])\n",
    "\n",
    "    nuc_intensity = nuc_csv_df.loc[:, ['raw core']]\n",
    "    nuc_prc[count, :] = np.percentile(nuc_intensity, [10, 25, 50, 75, 90])\n",
    "\n",
    "nuc_prc_df = pd.DataFrame(nuc_prc, columns=['nuc_prc_10', 'nuc_prc_25',\n",
    "                                            'nuc_prc_50', 'nuc_prc_75', 'nuc_prc_90'])\n",
    "\n",
    "img_intensity_df = pd.concat([img_intensity_df, nuc_prc_df], axis=1)\n",
    "\n",
    "# %%\n",
    "csv_file = nuc_path + img_name + '_nuclei_only.csv'\n",
    "nuc_csv_df = pd.read_csv(csv_file, skiprows=[1])\n",
    "# %% NOW DEALING WITH SYNAPSES\n",
    "# load classified synapses\n",
    "\n",
    "syn_path = 'D:/Code/repos/psd95_segmentation/data/raw/csv/pallium/syn/'\n",
    "img_names = img_intensity_df.iloc[:, 1]\n",
    "link_head = 'https://synapse.isrd.isi.edu'\n",
    "\n",
    "for count, img_name in enumerate(img_names):\n",
    "    segmentations = info_df.loc[info_df['Source Image'] == img_name,\n",
    "                                ['RID', 'classifier_name', 'Segments Filtered URL']]\n",
    "    for index, segmentation in segmentations.iterrows():\n",
    "        rid = segmentation[0]\n",
    "        cl_name = segmentation[1]\n",
    "        url = segmentation[2]\n",
    "        csv_type = url.split('.')[1]\n",
    "        if csv_type == 'synapses_only' or csv_type == 'segments_only':\n",
    "            url = link_head + url\n",
    "            syn_csv = requests.get(url, allow_redirects=True)\n",
    "            open(syn_path + img_name + '_' + rid + '_' + csv_type + '.csv',\n",
    "                 'wb').write(syn_csv.content)\n",
    "# %% NOW DEALING WITH SYNAPSES\n",
    "# load classified synapses\n",
    "\n",
    "syn_path = 'D:/Code/repos/psd95_segmentation/data/raw/csv/pallium/syn/'\n",
    "img_names = img_intensity_df.iloc[:, 1]\n",
    "syn_prc = np.zeros((len(img_names), 5))\n",
    "img_w_two = []\n",
    "\n",
    "for count, img_name in enumerate(img_names):\n",
    "    num_syn = 0\n",
    "    segmentations = info_df.loc[info_df['Source Image'] == img_name,\n",
    "                                ['RID', 'classifier_name', 'Segments Filtered URL']]\n",
    "    for index, segmentation in segmentations.iterrows():\n",
    "        rid = segmentation[0]\n",
    "        cl_name = segmentation[1]\n",
    "        url = segmentation[2]\n",
    "        csv_type = url.split('.')[1]\n",
    "        if csv_type == 'synapses_only' or csv_type == 'segments_only':\n",
    "            csv_file = syn_path + img_name + '_' + rid + '_' + csv_type + '.csv'\n",
    "            if Path(csv_file).exists():\n",
    "                num_syn = num_syn + 1\n",
    "                if num_syn > 1:\n",
    "                    img_w_two.append(img_name)\n",
    "                    print(f\"{img_name} {num_syn}\")\n",
    "\n",
    "# %% Add percentiles for synapses\n",
    "syn_prc = np.zeros((len(img_names), 5))\n",
    "\n",
    "for count, img_name in enumerate(img_names):\n",
    "    done = 0\n",
    "    segmentations = info_df.loc[info_df['Source Image'] == img_name,\n",
    "                                ['RID', 'classifier_name', 'Segments Filtered URL']]\n",
    "    for index, segmentation in segmentations.iterrows():\n",
    "        rid = segmentation[0]\n",
    "        cl_name = segmentation[1]\n",
    "        url = segmentation[2]\n",
    "        csv_type = url.split('.')[1]\n",
    "        if csv_type == 'synapses_only':\n",
    "            csv_file = syn_path + img_name + '_' + rid + '_' + csv_type + '.csv'\n",
    "            if Path(csv_file).exists() and done == 0:\n",
    "                done = 1\n",
    "                syn_csv_df = pd.read_csv(csv_file, skiprows=[1])\n",
    "                syn_intensity = syn_csv_df.loc[:, ['raw core']]\n",
    "                syn_prc[count, :] = np.percentile(syn_intensity,\n",
    "                                                  [10, 25, 50, 75, 90])\n",
    "\n",
    "syn_prc_df = pd.DataFrame(syn_prc, columns=['syn_prc_10', 'syn_prc_25',\n",
    "                                            'syn_prc_50', 'syn_prc_75', 'syn_prc_90'])\n",
    "\n",
    "img_intensity_df = pd.concat([img_intensity_df, syn_prc_df], axis=1)\n",
    "\n",
    "# %%\n",
    "feature = 'syn_prc_90'\n",
    "fig = plot_boxplot(img_intensity_df, 'Year', feature)\n",
    "fig.savefig(feature + '.png')\n",
    "\n",
    "# %%\n",
    "\n",
    "# %% save table\n",
    "img_intensity_df.to_csv('intensity_over_years.csv')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}